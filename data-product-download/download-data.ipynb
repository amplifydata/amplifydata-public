{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1589af6c-1edb-4eb7-b2cb-f5ce4333eaa2",
   "metadata": {},
   "source": [
    "# Amplify Data API: Downloading Product Data\n",
    "\n",
    "This notebook will walk you through the process of downloading your data product's data via the Amplify API\n",
    "\n",
    "To follow this example, clone this repo and open this notebook: \n",
    "```\n",
    "git clone git@github.com:amplifydata/amplifydata-public.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd30f8-6b99-4341-b5ad-86974d0273f4",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Make sure you follow the [data-product-download/README.md]() setup directions before running this notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b11cb87a-7f42-4cc9-b868-21ed0d78d220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm==4.65.0 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: python-dotenv==1.0.0 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: requests==2.28.1 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (2.28.1)\n",
      "Requirement already satisfied: click==8.1.3 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (8.1.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 3)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 3)) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (from requests==2.28.1->-r requirements.txt (line 3)) (2022.9.24)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98c2720a-727b-4dcc-861f-578a34f2dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv #install with requirements\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "AMPLIFY_API_KEY = os.environ[\"AMPLIFY_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e81a27-3979-4084-96af-7e8e8ad033a0",
   "metadata": {},
   "source": [
    "## Getting Product Data\n",
    "\n",
    "Getting your products data is a two step process. This notebook will walk you through the following steps\n",
    "\n",
    "1. Hit the api to get a list of \"download_links\". These links are [aws s3 presigned url's](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html), which can be used to download data\n",
    "2. Use the download links to download the data to your machine. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8bbc7-ff29-4f55-b82a-87fc8084dd5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Step 1: Request Your Download links\n",
    "\n",
    "\n",
    "The first step is to make a request to the Amplify Data API for the product with data you intend to download. \n",
    "\n",
    "\n",
    "We will use the `/external-api/v2/products/{product_id}/files` endpoint to obtain \"download_links\" for your project, which are links we will use to download the product data. \n",
    "\n",
    "Here is an example response, with the fields expalined below: \n",
    "\n",
    "\n",
    "**Example Response**\n",
    "```json\n",
    "{\n",
    "    \"download_links\": [\n",
    "        \"https://amplifydata-development-dev.s3.amazonaws.com/...\"\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"num_files\": 1,\n",
    "        \"total_size_mb\": 13.7,\n",
    "        \"avg_file_size_mb\": 13.7,\n",
    "        \"expires_at\": \"2023-06-29 13:56:10\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "* download_links: this key holds a list of [aws s3 presigned url's](https://docs.aws.amazon.com/AmazonS3/latest/userguide/ShareObjectPreSignedURL.html). These can be used to download the data, we will show examples later in this notebook\n",
    "* Metadata: a dictionary of info about the product you are downloading\n",
    "    * num_files: the number of files (and correspondingly, download_links) that are included in the response\n",
    "    * total_size_mb: the total size of all files available for download\n",
    "    * avg_file_size_mb: the avg file size of the files available for download\n",
    "    * **expires_at**: This is the date at which the returned download_links will no longer work. You will have to request new ones after this date. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f362314-29f3-4dd7-9cc1-375f90e22c4f",
   "metadata": {},
   "source": [
    "## Your API URL\n",
    "\n",
    "The Amplify Subscription Card (in the frontend) should provide you are url to use to download a product's data. \n",
    "\n",
    "**Replace the `PRODUCT_API_URL` variable below with the provided api url for your request.** \n",
    "\n",
    "After replacing the `PRODUCT_API_URL`, you can run the following code to get the download_links for your product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "703b3262-06a3-47ff-bf6c-f1073e75e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata = {\n",
      "    \"num_files\": 1,\n",
      "    \"total_size_mb\": 13.7,\n",
      "    \"avg_file_size_mb\": 13.7,\n",
      "    \"expires_at\": \"2023-06-29 15:08:18\"\n",
      "}\n",
      "download_links = [\n",
      "    \"https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=wgzXD0ethF9oEQGu%2FMX3fKDqWe4%3D&Expires=1688065698\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "import json\n",
    "\n",
    "\n",
    "# product_id = \"b16f31fd-41e1-4dd9-839d-f67d06af95c0\"\n",
    "# product_url = \"https://dev.amplifydata.io/external-api/v2/products/fb4e397f-d464-4851-93b1-0519f3544550/files\"\n",
    "\n",
    "## REPLACE WITH THE URL FROM YOUR SUBSCRIPTION!! \n",
    "# PRODUCT_API_URL = \"https://dev.amplifydata.io/external-api/v2/products/e61ba35e-2a7e-4a7a-8788-284a92012cdd/files\"\n",
    "PRODUCT_API_URL = \"https://dev.amplifydata.io/external-api/v2/products/b16f31fd-41e1-4dd9-839d-f67d06af95c0/files\"\n",
    "\n",
    "\n",
    "res = requests.get(\n",
    "    PRODUCT_API_URL,\n",
    "    headers = {\n",
    "        \"X-API-KEY\": AMPLIFY_API_KEY,\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    ")\n",
    "\n",
    "if res.status_code != 200:\n",
    "    raise Exception(res.json())\n",
    "    \n",
    "data = res.json()\n",
    "\n",
    "# json used to \"prettify\" notebook output, only shows up to 10 download links\n",
    "print(f'metadata = {json.dumps(data[\"metadata\"], indent=4)}')\n",
    "print(f'download_links = {json.dumps(data[\"download_links\"][:10], indent=4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b153a-05db-41ff-b835-7dc5dff6ef0e",
   "metadata": {},
   "source": [
    "## Download your data\n",
    "\n",
    "Now that we have a successful response from the API, we can use the `download_links` to do what we came here for, and download the data itself to your machine. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2cb10-422d-4e93-84d1-24bd4f6a956c",
   "metadata": {},
   "source": [
    "### Download Directly to files\n",
    "\n",
    "If you are downloading data for a large product, this process can take a long time (it is largely dependent on your network connection).\n",
    "\n",
    "The following code has a function `download_file` that we will use to download your data to a local file. \n",
    "\n",
    "**Make sure the directory you are storing the file in already exists.** You can use the DATA_DIR var in the next cell to manage where the data is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "403421be-8e88-47cf-8257-b23020d8c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_dir\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26ac6fbd-27d7-4768-8011-8b71e673a1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data_dir: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir $DATA_DIR # creates a directory relative to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47fa2cfb-6da3-498a-8e89-a5a1e60bf75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=wgzXD0ethF9oEQGu%2FMX3fKDqWe4%3D&Expires=1688065698 to data_dir/file-0.csv\n"
     ]
    }
   ],
   "source": [
    "def download_file(url: str, filepath: str):\n",
    "    \"\"\"\n",
    "    This function downloads the data available in 'url' and writes it to file of name filepath\n",
    "    Args:\n",
    "        url (str): download link that is provided by amplify api response \n",
    "        filepath (str): filepath file to write data to (directory must already exist!)\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {url} to {filepath}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for index, i_link in enumerate(data[\"download_links\"]):\n",
    "    download_file(i_link, f\"{DATA_DIR}/file-{index}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b901e-4d76-4798-98a0-ed693157d728",
   "metadata": {},
   "source": [
    "### Direct to file with progress bar! \n",
    "\n",
    "An extra feature that is nice for longer downloads is a progress bar for each file download. \n",
    "The code is very similar, except that we need to install tqdm before to handle the progress bar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "905b5bac-975e-4304-b159-f4fb7a9fffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "79a1ee3a-ce65-46f5-9555-403f947fe275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 14.4M/14.4M [00:00<00:00, 25.8MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=wgzXD0ethF9oEQGu%2FMX3fKDqWe4%3D&Expires=1688065698 to data-dir/file-0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url: str, filepath: str):\n",
    "    \"\"\"\n",
    "    This function downloads the data available in 'url' and writes it to file of name filepath\n",
    "    Args:\n",
    "        url (str): download link that is provided by amplify api response \n",
    "        filepath (str): filepath file to write data to (directory must already exist!)\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, position=0, leave=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "                progress_bar.update(len(chunk))\n",
    "        progress_bar.close()\n",
    "        print(f\"Downloaded {url} to {filepath}\")\n",
    "\n",
    "\n",
    "for index, i_link in enumerate(data[\"download_links\"]):\n",
    "    download_file(i_link, f\"data-dir/file-{index}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be6f62-5241-4c86-9c8e-08a0c49e077c",
   "metadata": {},
   "source": [
    "## Use Pandas to Download \n",
    "\n",
    "You can also download your data directly into a pandas dataframe. \n",
    "\n",
    "You can pass a download link directly to `pd.read_csv`! \n",
    "\n",
    "Here's an example reading a single download_link into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb6a16db-7980-44c7-9244-6b5696243992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "      <th>CREATED_AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200001.0</td>\n",
       "      <td>13726.0</td>\n",
       "      <td>F</td>\n",
       "      <td>99406.41</td>\n",
       "      <td>1994-02-21</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eep. final deposits are after t</td>\n",
       "      <td>2020-07-26 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200002.0</td>\n",
       "      <td>129376.0</td>\n",
       "      <td>O</td>\n",
       "      <td>256838.41</td>\n",
       "      <td>1997-04-14</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ke carefully. blithely regular epitaphs are am...</td>\n",
       "      <td>2023-03-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200003.0</td>\n",
       "      <td>141613.0</td>\n",
       "      <td>O</td>\n",
       "      <td>150849.49</td>\n",
       "      <td>1997-11-24</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cial accounts. theodolites are carefully. pend...</td>\n",
       "      <td>2022-12-01 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200004.0</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>O</td>\n",
       "      <td>178688.27</td>\n",
       "      <td>1996-12-09</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sual requests against the always special packa...</td>\n",
       "      <td>2021-07-20 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200005.0</td>\n",
       "      <td>97687.0</td>\n",
       "      <td>O</td>\n",
       "      <td>261742.31</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t slyly above the pending, final accounts? reg...</td>\n",
       "      <td>2020-12-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0   4200001.0    13726.0             F      99406.41  1994-02-21   \n",
       "1   4200002.0   129376.0             O     256838.41  1997-04-14   \n",
       "2   4200003.0   141613.0             O     150849.49  1997-11-24   \n",
       "3   4200004.0    23515.0             O     178688.27  1996-12-09   \n",
       "4   4200005.0    97687.0             O     261742.31  1997-02-01   \n",
       "\n",
       "   O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0         3-MEDIUM  Clerk#000000128             0.0   \n",
       "1  4-NOT SPECIFIED  Clerk#000000281             0.0   \n",
       "2  4-NOT SPECIFIED  Clerk#000000585             0.0   \n",
       "3           2-HIGH  Clerk#000000632             0.0   \n",
       "4           2-HIGH  Clerk#000000562             0.0   \n",
       "\n",
       "                                           O_COMMENT               CREATED_AT  \n",
       "0                    eep. final deposits are after t  2020-07-26 18:37:56.448  \n",
       "1  ke carefully. blithely regular epitaphs are am...  2023-03-09 19:37:56.448  \n",
       "2  cial accounts. theodolites are carefully. pend...  2022-12-01 19:37:56.448  \n",
       "3  sual requests against the always special packa...  2021-07-20 18:37:56.448  \n",
       "4  t slyly above the pending, final accounts? reg...  2020-12-09 19:37:56.448  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Single file example\n",
    "df = pd.read_csv(data[\"download_links\"][0]) # can only pass a single download url\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8047066-aafa-4d7c-b88a-4b4d27a654ae",
   "metadata": {},
   "source": [
    "#### Read all download links into a dataframe\n",
    "\n",
    "Here is an example of how you can use pandas to read multiple download_links into a single dataframe. \n",
    "\n",
    "**WARNING**: for large products, this can take a long time, with no indication of progress. For larger downloads, we suggest using the download to file with a progress bar example above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a88cfd8-9c0e-4d55-83c5-13bb73ccdf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "      <th>CREATED_AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200001.0</td>\n",
       "      <td>13726.0</td>\n",
       "      <td>F</td>\n",
       "      <td>99406.41</td>\n",
       "      <td>1994-02-21</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eep. final deposits are after t</td>\n",
       "      <td>2020-07-26 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200002.0</td>\n",
       "      <td>129376.0</td>\n",
       "      <td>O</td>\n",
       "      <td>256838.41</td>\n",
       "      <td>1997-04-14</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ke carefully. blithely regular epitaphs are am...</td>\n",
       "      <td>2023-03-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200003.0</td>\n",
       "      <td>141613.0</td>\n",
       "      <td>O</td>\n",
       "      <td>150849.49</td>\n",
       "      <td>1997-11-24</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cial accounts. theodolites are carefully. pend...</td>\n",
       "      <td>2022-12-01 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200004.0</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>O</td>\n",
       "      <td>178688.27</td>\n",
       "      <td>1996-12-09</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sual requests against the always special packa...</td>\n",
       "      <td>2021-07-20 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200005.0</td>\n",
       "      <td>97687.0</td>\n",
       "      <td>O</td>\n",
       "      <td>261742.31</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t slyly above the pending, final accounts? reg...</td>\n",
       "      <td>2020-12-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0   4200001.0    13726.0             F      99406.41  1994-02-21   \n",
       "1   4200002.0   129376.0             O     256838.41  1997-04-14   \n",
       "2   4200003.0   141613.0             O     150849.49  1997-11-24   \n",
       "3   4200004.0    23515.0             O     178688.27  1996-12-09   \n",
       "4   4200005.0    97687.0             O     261742.31  1997-02-01   \n",
       "\n",
       "   O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0         3-MEDIUM  Clerk#000000128             0.0   \n",
       "1  4-NOT SPECIFIED  Clerk#000000281             0.0   \n",
       "2  4-NOT SPECIFIED  Clerk#000000585             0.0   \n",
       "3           2-HIGH  Clerk#000000632             0.0   \n",
       "4           2-HIGH  Clerk#000000562             0.0   \n",
       "\n",
       "                                           O_COMMENT               CREATED_AT  \n",
       "0                    eep. final deposits are after t  2020-07-26 18:37:56.448  \n",
       "1  ke carefully. blithely regular epitaphs are am...  2023-03-09 19:37:56.448  \n",
       "2  cial accounts. theodolites are carefully. pend...  2022-12-01 19:37:56.448  \n",
       "3  sual requests against the always special packa...  2021-07-20 18:37:56.448  \n",
       "4  t slyly above the pending, final accounts? reg...  2020-12-09 19:37:56.448  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for i_download_link in data[\"download_links\"]:\n",
    "    i_df = pd.read_csv(i_download_link)\n",
    "    dfs.append(i_df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1c666-0096-4883-bafc-d1ff16c53952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
