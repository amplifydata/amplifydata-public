{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1589af6c-1edb-4eb7-b2cb-f5ce4333eaa2",
   "metadata": {},
   "source": [
    "# Amplify Data API: Downloading Product Data\n",
    "\n",
    "This notebook will walk you through the process of downloading your data product's data via the Amplify API\n",
    "\n",
    "To follow this example, clone this repo and open this notebook: \n",
    "```\n",
    "git clone git@github.com:amplifydata/amplifydata-public.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9c5a03-aed1-4fc5-a5fc-ab7a3f2d1ad2",
   "metadata": {},
   "source": [
    "## Auth\n",
    "\n",
    "First, you must obtain an `AMPLIFY_API_KEY` by following the [Generating the API Key](https://github.com/amplifydata/amplifydata-public/tree/main#generating-an-api-key) directions on this repo's readme. \n",
    "\n",
    "Next, you must make that value available as an environment variable. \n",
    "\n",
    "We use the following steps (but you can update this in any fashion you like):\n",
    "1. Create a `.env` in the same directory as this notebook\n",
    "\n",
    "We use the name `AMPLIFY_API_KEY`\n",
    "\n",
    "We suggest using [python-dotenv]() to load your `AMPLIFY_API_KEY` available as an environment variable. Be sure to create a `.env` file in the same directory as this notebook with this structure:\n",
    "```bash\n",
    "AMPLIFY_API_KEY=your-key-from-amplify\n",
    "```\n",
    "\n",
    "It will be used to authenticate you against our api endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fa96e08-b6a0-41ef-894c-ad60a7fcf2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c2720a-727b-4dcc-861f-578a34f2dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "    \n",
    "AMPLIFY_API_KEY = os.environ[\"AMPLIFY_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee20b2cb-570a-43c2-9fc5-b5058661d03d",
   "metadata": {},
   "source": [
    "## Create API Product Subscription\n",
    "\n",
    "**insert steps on subscription creation**\n",
    "\n",
    "1. go to UI\n",
    "2. get stuff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8bbc7-ff29-4f55-b82a-87fc8084dd5e",
   "metadata": {},
   "source": [
    "## Request Your Download links `/external-api/v2/products/{product_id}/files`\n",
    "\n",
    "Next, we are going to download the underlying files of your data product via the amplify api. \n",
    "\n",
    "\n",
    "**The API url for your product download should be available on the subscription you created for this project**\n",
    "\n",
    "\n",
    "Amplify's api works by returning a list of presigned download url's that can be used to download your data. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703b3262-06a3-47ff-bf6c-f1073e75e9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'download_links': ['https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=IejlOW3Lct4R67f1%2B1ju%2BX7yP8c%3D&Expires=1688061370'], 'metadata': {'num_files': 1, 'total_size_mb': 13.7, 'avg_file_size_mb': 13.7, 'expires_at': '2023-06-29 13:56:10'}}\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "\n",
    "product_id = \"b16f31fd-41e1-4dd9-839d-f67d06af95c0\"\n",
    "\n",
    "\n",
    "## REPLACE WITH THE URL FROM YOUR SUBSCRIPTION!! \n",
    "product_url = \"https://dev.amplifydata.io/external-api/v2/products/fb4e397f-d464-4851-93b1-0519f3544550/files\"\n",
    "\n",
    "\n",
    "product_url = \"https://dev.amplifydata.io/external-api/v2/products/b16f31fd-41e1-4dd9-839d-f67d06af95c0/files\"\n",
    "\n",
    "\n",
    "res = requests.get(\n",
    "    product_url,\n",
    "    headers = {\n",
    "        \"X-API-KEY\": AMPLIFY_API_KEY,\n",
    "        'accept': 'application/json'\n",
    "    }\n",
    ")\n",
    "\n",
    "if res.status_code != 200:\n",
    "    raise Exception(res.json())\n",
    "    \n",
    "data = res.json() # { \"download_links\": [], \"metadata\": {} }\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b153a-05db-41ff-b835-7dc5dff6ef0e",
   "metadata": {},
   "source": [
    "## Download your data\n",
    "\n",
    "Response structure: \n",
    "```json\n",
    "{\n",
    "    'download_links': [\n",
    "        list of urls used to download data\n",
    "    ], \n",
    "    'metdata': {\n",
    "        'num_files': \n",
    "        'total_size_mb': \n",
    "        avg_file_size_mb: \n",
    "        expires_at: \n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "With that request, you now have access to download your data! \n",
    "\n",
    "**insert section about expires at**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2cb10-422d-4e93-84d1-24bd4f6a956c",
   "metadata": {},
   "source": [
    "## Download Directly to file\n",
    "\n",
    "If you are downloading data for a large product, this process can take a long time (it is largely dependent on your network connection).\n",
    "\n",
    "The following cell has a function `download_file` that we will use to download your data to a local file. \n",
    "\n",
    "**Make sure the directory you are storing the file in already exists.** You can use the DATA_DIR var in the next cell to manage where the data is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "403421be-8e88-47cf-8257-b23020d8c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_dir\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26ac6fbd-27d7-4768-8011-8b71e673a1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data_dir: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir $DATA_DIR # creates a directory relative to this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47fa2cfb-6da3-498a-8e89-a5a1e60bf75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=IejlOW3Lct4R67f1%2B1ju%2BX7yP8c%3D&Expires=1688061370 to data_dir/file-0.csv\n"
     ]
    }
   ],
   "source": [
    "def download_file(url: str, filepath: str):\n",
    "    \"\"\"\n",
    "    This function downloads the data available in 'url' and writes it to file of name filepath\n",
    "    Args:\n",
    "        url (str): download link that is provided by amplify api response \n",
    "        filepath (str): filepath file to write data to (directory must already exist!)\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "        print(f\"Downloaded {url} to {filepath}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for index, i_link in enumerate(data[\"download_links\"]):\n",
    "    download_file(i_link, f\"{DATA_DIR}/file-{index}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b901e-4d76-4798-98a0-ed693157d728",
   "metadata": {},
   "source": [
    "### Direct to file with progress bar! \n",
    "\n",
    "An extra feature that is nice for longer downloads is a progress bar for each file download. \n",
    "The code is very similar, except that we need to install tqdm before and handle the progress bar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "905b5bac-975e-4304-b159-f4fb7a9fffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /Users/nicktorba/miniconda3/envs/amplify/lib/python3.10/site-packages (4.65.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79a1ee3a-ce65-46f5-9555-403f947fe275",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 14.4M/14.4M [00:00<00:00, 21.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded https://amplifydata-development-dev.s3.amazonaws.com/snowflake%20orders%20100k--b16f31fd-41e1-4dd9-839d-f67d06af95c0/file.csv?AWSAccessKeyId=AKIASC5E62QHCPMXWWSX&Signature=IejlOW3Lct4R67f1%2B1ju%2BX7yP8c%3D&Expires=1688061370 to data-dir/file-0.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url: str, filepath: str):\n",
    "    \"\"\"\n",
    "    This function downloads the data available in 'url' and writes it to file of name filepath\n",
    "    Args:\n",
    "        url (str): download link that is provided by amplify api response \n",
    "        filepath (str): filepath file to write data to (directory must already exist!)\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        total_size = int(r.headers.get('content-length', 0))\n",
    "        progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, position=0, leave=True)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                f.write(chunk)\n",
    "                progress_bar.update(len(chunk))\n",
    "        progress_bar.close()\n",
    "        print(f\"Downloaded {url} to {filepath}\")\n",
    "\n",
    "\n",
    "for index, i_link in enumerate(data[\"download_links\"]):\n",
    "    download_file(i_link, f\"data-dir/file-{index}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0be6f62-5241-4c86-9c8e-08a0c49e077c",
   "metadata": {},
   "source": [
    "## Use Pandas to Download \n",
    "\n",
    "You can also download your data directly into a pandas dataframe. \n",
    "\n",
    "You can pass a download link directly to `pd.read_csv`! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb6a16db-7980-44c7-9244-6b5696243992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "      <th>CREATED_AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200001.0</td>\n",
       "      <td>13726.0</td>\n",
       "      <td>F</td>\n",
       "      <td>99406.41</td>\n",
       "      <td>1994-02-21</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eep. final deposits are after t</td>\n",
       "      <td>2020-07-26 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200002.0</td>\n",
       "      <td>129376.0</td>\n",
       "      <td>O</td>\n",
       "      <td>256838.41</td>\n",
       "      <td>1997-04-14</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ke carefully. blithely regular epitaphs are am...</td>\n",
       "      <td>2023-03-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200003.0</td>\n",
       "      <td>141613.0</td>\n",
       "      <td>O</td>\n",
       "      <td>150849.49</td>\n",
       "      <td>1997-11-24</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cial accounts. theodolites are carefully. pend...</td>\n",
       "      <td>2022-12-01 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200004.0</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>O</td>\n",
       "      <td>178688.27</td>\n",
       "      <td>1996-12-09</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sual requests against the always special packa...</td>\n",
       "      <td>2021-07-20 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200005.0</td>\n",
       "      <td>97687.0</td>\n",
       "      <td>O</td>\n",
       "      <td>261742.31</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t slyly above the pending, final accounts? reg...</td>\n",
       "      <td>2020-12-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0   4200001.0    13726.0             F      99406.41  1994-02-21   \n",
       "1   4200002.0   129376.0             O     256838.41  1997-04-14   \n",
       "2   4200003.0   141613.0             O     150849.49  1997-11-24   \n",
       "3   4200004.0    23515.0             O     178688.27  1996-12-09   \n",
       "4   4200005.0    97687.0             O     261742.31  1997-02-01   \n",
       "\n",
       "   O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0         3-MEDIUM  Clerk#000000128             0.0   \n",
       "1  4-NOT SPECIFIED  Clerk#000000281             0.0   \n",
       "2  4-NOT SPECIFIED  Clerk#000000585             0.0   \n",
       "3           2-HIGH  Clerk#000000632             0.0   \n",
       "4           2-HIGH  Clerk#000000562             0.0   \n",
       "\n",
       "                                           O_COMMENT               CREATED_AT  \n",
       "0                    eep. final deposits are after t  2020-07-26 18:37:56.448  \n",
       "1  ke carefully. blithely regular epitaphs are am...  2023-03-09 19:37:56.448  \n",
       "2  cial accounts. theodolites are carefully. pend...  2022-12-01 19:37:56.448  \n",
       "3  sual requests against the always special packa...  2021-07-20 18:37:56.448  \n",
       "4  t slyly above the pending, final accounts? reg...  2020-12-09 19:37:56.448  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## Single file example\n",
    "df = pd.read_csv(data[\"download_links\"][0]) # can only pass a single download url\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a88cfd8-9c0e-4d55-83c5-13bb73ccdf2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O_ORDERKEY</th>\n",
       "      <th>O_CUSTKEY</th>\n",
       "      <th>O_ORDERSTATUS</th>\n",
       "      <th>O_TOTALPRICE</th>\n",
       "      <th>O_ORDERDATE</th>\n",
       "      <th>O_ORDERPRIORITY</th>\n",
       "      <th>O_CLERK</th>\n",
       "      <th>O_SHIPPRIORITY</th>\n",
       "      <th>O_COMMENT</th>\n",
       "      <th>CREATED_AT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200001.0</td>\n",
       "      <td>13726.0</td>\n",
       "      <td>F</td>\n",
       "      <td>99406.41</td>\n",
       "      <td>1994-02-21</td>\n",
       "      <td>3-MEDIUM</td>\n",
       "      <td>Clerk#000000128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>eep. final deposits are after t</td>\n",
       "      <td>2020-07-26 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200002.0</td>\n",
       "      <td>129376.0</td>\n",
       "      <td>O</td>\n",
       "      <td>256838.41</td>\n",
       "      <td>1997-04-14</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ke carefully. blithely regular epitaphs are am...</td>\n",
       "      <td>2023-03-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200003.0</td>\n",
       "      <td>141613.0</td>\n",
       "      <td>O</td>\n",
       "      <td>150849.49</td>\n",
       "      <td>1997-11-24</td>\n",
       "      <td>4-NOT SPECIFIED</td>\n",
       "      <td>Clerk#000000585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cial accounts. theodolites are carefully. pend...</td>\n",
       "      <td>2022-12-01 19:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200004.0</td>\n",
       "      <td>23515.0</td>\n",
       "      <td>O</td>\n",
       "      <td>178688.27</td>\n",
       "      <td>1996-12-09</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sual requests against the always special packa...</td>\n",
       "      <td>2021-07-20 18:37:56.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200005.0</td>\n",
       "      <td>97687.0</td>\n",
       "      <td>O</td>\n",
       "      <td>261742.31</td>\n",
       "      <td>1997-02-01</td>\n",
       "      <td>2-HIGH</td>\n",
       "      <td>Clerk#000000562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>t slyly above the pending, final accounts? reg...</td>\n",
       "      <td>2020-12-09 19:37:56.448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O_ORDERKEY  O_CUSTKEY O_ORDERSTATUS  O_TOTALPRICE O_ORDERDATE  \\\n",
       "0   4200001.0    13726.0             F      99406.41  1994-02-21   \n",
       "1   4200002.0   129376.0             O     256838.41  1997-04-14   \n",
       "2   4200003.0   141613.0             O     150849.49  1997-11-24   \n",
       "3   4200004.0    23515.0             O     178688.27  1996-12-09   \n",
       "4   4200005.0    97687.0             O     261742.31  1997-02-01   \n",
       "\n",
       "   O_ORDERPRIORITY          O_CLERK  O_SHIPPRIORITY  \\\n",
       "0         3-MEDIUM  Clerk#000000128             0.0   \n",
       "1  4-NOT SPECIFIED  Clerk#000000281             0.0   \n",
       "2  4-NOT SPECIFIED  Clerk#000000585             0.0   \n",
       "3           2-HIGH  Clerk#000000632             0.0   \n",
       "4           2-HIGH  Clerk#000000562             0.0   \n",
       "\n",
       "                                           O_COMMENT               CREATED_AT  \n",
       "0                    eep. final deposits are after t  2020-07-26 18:37:56.448  \n",
       "1  ke carefully. blithely regular epitaphs are am...  2023-03-09 19:37:56.448  \n",
       "2  cial accounts. theodolites are carefully. pend...  2022-12-01 19:37:56.448  \n",
       "3  sual requests against the always special packa...  2021-07-20 18:37:56.448  \n",
       "4  t slyly above the pending, final accounts? reg...  2020-12-09 19:37:56.448  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read all download links into a dataframe\n",
    "\n",
    "## WARNING: for large products, this can take a long time\n",
    "## be sure to save this data locally so you don't have to wait for the download process each time\n",
    "dfs = []\n",
    "\n",
    "for i_download_link in data[\"download_links\"]:\n",
    "    i_df = pd.read_csv(i_download_link)\n",
    "    dfs.append(i_df)\n",
    "\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab1c666-0096-4883-bafc-d1ff16c53952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
